{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'utils' from '/Users/diogomesquita/Documents/nyu/2y/nlp/homeworks/hw2/utils.py'>\n",
      "<module 'data' from '/Users/diogomesquita/Documents/nyu/2y/nlp/homeworks/hw2/data.py'>\n",
      "<module 'models' from '/Users/diogomesquita/Documents/nyu/2y/nlp/homeworks/hw2/models.py'>\n",
      "<module 'train_helpers' from '/Users/diogomesquita/Documents/nyu/2y/nlp/homeworks/hw2/train_helpers.py'>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import io\n",
    "import string\n",
    "import pickle as pkl\n",
    "from collections import Counter\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import imp\n",
    "import utils\n",
    "import data\n",
    "import models\n",
    "import train_helpers\n",
    "\n",
    "print(imp.reload(utils))\n",
    "print(imp.reload(data))\n",
    "print(imp.reload(models))\n",
    "print(imp.reload(train_helpers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS:\n",
    "VOCAB_SIZE = 15000\n",
    "PAD = '<pad>'\n",
    "UNK = '<unk>'\n",
    "emb_dim = 300\n",
    "BATCH_SIZE = 32\n",
    "data_dir = \"hw2_data\"\n",
    "vocab_dir = \"vocab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_EVERYTHING = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_raw = pd.read_csv(os.path.join(data_dir, \"snli_train.tsv\"), sep='\\t')\n",
    "val_data_raw = pd.read_csv(os.path.join(data_dir, \"snli_val.tsv\"), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ix = {\n",
    "    'contradiction': 0,\n",
    "    'entailment': 1,\n",
    "    'neutral': 2\n",
    "}\n",
    "\n",
    "def label_to_ix(df):\n",
    "    return df['label'].apply(lambda x: labels_ix[x])\n",
    "\n",
    "train_target = label_to_ix(train_data_raw)\n",
    "val_target = label_to_ix(val_data_raw)\n",
    "\n",
    "utils.save_pkl_data(train_target, 'snli_train_target.p')\n",
    "utils.save_pkl_data(val_target, 'snli_val_target.p')\n",
    "\n",
    "train_data = train_data_raw.loc[:, ['sentence1', 'sentence2']]\n",
    "val_data = val_data_raw.loc[:, ['sentence1', 'sentence2']]\n",
    "\n",
    "train_data.columns = ['premise', 'hypothesis']\n",
    "val_data.columns = ['premise', 'hypothesis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A young girl in a pink shirt sitting on a dock...</td>\n",
       "      <td>A young girl watching the sunset over the water .</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A woman is smiling while the man next to her i...</td>\n",
       "      <td>Two people are next to each other .</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Across the river , you can see a large building .</td>\n",
       "      <td>The large building is full of apartments and t...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a man in white shorts and a black shirt is par...</td>\n",
       "      <td>A man is riding a jetski on the ocean .</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Four black dogs run together on bright green g...</td>\n",
       "      <td>Four dogs are preparing to be launched into sp...</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  A young girl in a pink shirt sitting on a dock...   \n",
       "1  A woman is smiling while the man next to her i...   \n",
       "2  Across the river , you can see a large building .   \n",
       "3  a man in white shorts and a black shirt is par...   \n",
       "4  Four black dogs run together on bright green g...   \n",
       "\n",
       "                                           sentence2          label  \n",
       "0  A young girl watching the sunset over the water .        neutral  \n",
       "1                Two people are next to each other .     entailment  \n",
       "2  The large building is full of apartments and t...        neutral  \n",
       "3            A man is riding a jetski on the ocean .  contradiction  \n",
       "4  Four dogs are preparing to be launched into sp...  contradiction  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A young girl in a pink shirt sitting on a dock...</td>\n",
       "      <td>A young girl watching the sunset over the water .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A woman is smiling while the man next to her i...</td>\n",
       "      <td>Two people are next to each other .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Across the river , you can see a large building .</td>\n",
       "      <td>The large building is full of apartments and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a man in white shorts and a black shirt is par...</td>\n",
       "      <td>A man is riding a jetski on the ocean .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Four black dogs run together on bright green g...</td>\n",
       "      <td>Four dogs are preparing to be launched into sp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  A young girl in a pink shirt sitting on a dock...   \n",
       "1  A woman is smiling while the man next to her i...   \n",
       "2  Across the river , you can see a large building .   \n",
       "3  a man in white shorts and a black shirt is par...   \n",
       "4  Four black dogs run together on bright green g...   \n",
       "\n",
       "                                          hypothesis  \n",
       "0  A young girl watching the sunset over the water .  \n",
       "1                Two people are next to each other .  \n",
       "2  The large building is full of apartments and t...  \n",
       "3            A man is riding a jetski on the ocean .  \n",
       "4  Four dogs are preparing to be launched into sp...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    1\n",
       "2    2\n",
       "3    0\n",
       "4    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#examples train:  100000\n",
      "#examples val:  1000\n"
     ]
    }
   ],
   "source": [
    "n_train = len(train_data)\n",
    "n_val = len(val_data)\n",
    "print(\"#examples train: \", n_train)\n",
    "print(\"#examples val: \", n_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ix:  21110\n",
      "Premise:     Six men shielding their eyes from the sun\n",
      "Hypothesis:  People shield their eyes from the bright light .\n",
      "Label:       2\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(4364)\n",
    "rx = np.random.randint(0, n_train, 1)[0]\n",
    "print(\"ix: \", rx)\n",
    "print(\"Premise:    \", train_data.iloc[rx,0])\n",
    "print(\"Hypothesis: \", train_data.iloc[rx,1])\n",
    "print(\"Label:      \", train_target[rx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data(df):\n",
    "    for ix in range(len(df)):\n",
    "        if type(df.loc[ix, 'premise']) != str:\n",
    "            print(\"Bad premise at index: \", ix)\n",
    "        if type(df.loc[ix, 'hypothesis']) != str:\n",
    "            print(\"Bad hypothesis at index: \", ix)\n",
    "            \n",
    "validate_data(train_data)\n",
    "validate_data(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def remove_punctuation(tokens):\n",
    "    return [token.text.lower() for token in tokens if token.text not in string.punctuation]\n",
    "    \n",
    "def tokenize(data):\n",
    "    all_tokens = []\n",
    "    data_tok = []\n",
    "    for ix in tqdm.tqdm_notebook(range(len(data))):\n",
    "        premise = remove_punctuation(tokenizer(data.loc[ix, 'premise']))\n",
    "        hypothesis = remove_punctuation(tokenizer(data.loc[ix, 'hypothesis']))\n",
    "        all_tokens += premise + hypothesis\n",
    "        data_tok.append([premise, hypothesis])\n",
    "    return data_tok, all_tokens\n",
    "\n",
    "f_train = 'snli_train_tok.p'\n",
    "f_val = 'snli_val_tok.p'\n",
    "if RUN_EVERYTHING or not os.path.isfile(os.path.join(data_dir, f_train)):\n",
    "    print('running')\n",
    "    train_data_tok, all_tokens = tokenize(train_data)\n",
    "    val_data_tok, _ = tokenize(val_data)\n",
    "    utils.save_pkl_data(train_data_tok, f_train)\n",
    "    utils.save_pkl_data(all_tokens, 'snli_all_tokens.p')\n",
    "    utils.save_pkl_data(val_data_tok, f_val)\n",
    "elif os.path.isfile(os.path.join(data_dir, f_train)):\n",
    "    train_data_tok = utils.load_pkl_data(f_train)\n",
    "    all_tokens = utils.load_pkl_data('snli_all_tokens.p')\n",
    "    val_data_tok = utils.load_pkl_data(f_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number tokens:  2038281\n",
      "number unique tokens:  19643\n"
     ]
    }
   ],
   "source": [
    "print(\"number tokens: \", len(all_tokens))\n",
    "print(\"number unique tokens: \", len(set(all_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = np.array(tokens[1:], dtype=np.float32)\n",
    "    return data\n",
    "\n",
    "def build_vocab(all_tokens, tok2vec):\n",
    "    counts = Counter(all_tokens).most_common()\n",
    "    ind2tok = [PAD, UNK] + [token for token, count in counts if token in tok2vec]\n",
    "    tok2ind = {tok: ind for ind, tok in enumerate(ind2tok)}\n",
    "    ind2vec = np.zeros((len(ind2tok), emb_dim), dtype=np.float32)\n",
    "    ind2vec[tok2ind[UNK], :] = np.random.uniform(low=-1, size=(emb_dim,))\n",
    "    for ix, tok in tqdm.tqdm_notebook(enumerate(ind2tok)):\n",
    "        if ix < 2:\n",
    "            continue\n",
    "        ind2vec[ix, :] = tok2vec[tok]\n",
    "    return ind2tok, tok2ind, torch.from_numpy(ind2vec)\n",
    "    \n",
    "if RUN_EVERYTHING or not os.path.isfile(os.path.join(vocab_dir, 'ind2vec.p')):\n",
    "    print('running')\n",
    "    tok2vec = load_vectors('wiki-news-300d-1M.vec')\n",
    "    ind2tok, tok2ind, ind2vec = build_vocab(all_tokens, tok2vec)\n",
    "    utils.save_pkl_data(ind2tok, 'ind2tok.p', data_dir='vocab')\n",
    "    utils.save_pkl_data(tok2ind, 'tok2ind.p', data_dir='vocab')\n",
    "    utils.save_pkl_data(ind2vec, 'ind2vec.p', data_dir='vocab')\n",
    "else:\n",
    "    ind2tok = utils.load_pkl_data('ind2tok.p', data_dir='vocab')\n",
    "    tok2ind = utils.load_pkl_data('tok2ind.p', data_dir='vocab')\n",
    "    ind2vec = utils.load_pkl_data('ind2vec.p', data_dir='vocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of lookup table:  torch.Size([18107, 300])\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of lookup table: \", ind2vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_indices(data):\n",
    "    data_ind = []\n",
    "    for ix, (premise, hypothesis) in enumerate(data):\n",
    "        if ix % 5000 == 4999:\n",
    "            print(f\"[{ix}/100000]\")\n",
    "        premise_ind = [tok2ind[tok] if tok in tok2ind else tok2ind[UNK] for tok in premise]\n",
    "        hypothesis_ind = [tok2ind[tok] if tok in tok2ind else tok2ind[UNK] for tok in hypothesis]\n",
    "        data_ind.append([premise_ind, hypothesis_ind])\n",
    "    return data_ind\n",
    "\n",
    "if RUN_EVERYTHING or not os.path.isfile(os.path.join(data_dir, 'snli_train_ind.p')):\n",
    "    print('running')\n",
    "    train_ind = data_indices(train_data_tok)\n",
    "    val_ind = data_indices(val_data_tok)\n",
    "    utils.save_pkl_data(train_ind, 'snli_train_ind.p')\n",
    "    utils.save_pkl_data(val_ind, 'snli_val_ind.p')\n",
    "else:\n",
    "    train_ind = utils.load_pkl_data('snli_train_ind.p')\n",
    "    val_ind = utils.load_pkl_data('snli_val_ind.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(len(train_ind)):\n",
    "    assert(len(train_ind[ix][0]) == len(train_data_tok[ix][0]))\n",
    "    assert(len(train_ind[ix][1]) == len(train_data_tok[ix][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL = True\n",
    "if SMALL:\n",
    "    train_dataset = data.SNLI_Dataset(train_ind[:5*32], train_target)\n",
    "else:\n",
    "    train_dataset = data.SNLI_Dataset(train_ind, train_target)\n",
    "val_dataset = data.SNLI_Dataset(val_ind, val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=data.collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=data.collate_fn)\n",
    "\n",
    "# model\n",
    "ind2vec = utils.load_pkl_data('ind2vec.p', data_dir='vocab')\n",
    "embed_size = 300\n",
    "premise_hidden_size = 300\n",
    "hypo_hidden_size = 300\n",
    "linear_hidden_size = 100\n",
    "num_layers = 1\n",
    "bidirectional = False\n",
    "snli_model_rnn = models.SNLI_Model_RNN(ind2vec,\n",
    "                                       embed_size,\n",
    "                                       premise_hidden_size,\n",
    "                                       hypo_hidden_size,\n",
    "                                       linear_hidden_size,\n",
    "                                       num_layers,\n",
    "                                       bidirectional)\n",
    "# optim\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam([param for param in snli_model_rnn.parameters() if param.requires_grad], lr=lr)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate time:\n",
      "\t\t-elapsed: 1.2391560077667236\n",
      "Epoch [1/2]; Batch [1/5]:\n",
      "\tTrain loss  : 1.100\n",
      "\tVal loss    : 1.099\n",
      "\tTrain acc   : 0.312\n",
      "\tVal acc     : 33.9\n",
      "\tBest val acc: 33.9\n",
      "\tBest model  : epoch_1_batch_1.pt\n",
      "\tElapsed     : 1.322725534439087 s\n",
      "\n",
      "evaluate time:\n",
      "\t\t-elapsed: 1.1616828441619873\n",
      "Epoch [1/2]; Batch [3/5]:\n",
      "\tTrain loss  : 1.100\n",
      "\tVal loss    : 1.098\n",
      "\tTrain acc   : 0.328\n",
      "\tVal acc     : 34.0\n",
      "\tBest val acc: 34.0\n",
      "\tBest model  : epoch_1_batch_3.pt\n",
      "\tElapsed     : 1.2340919971466064 s\n",
      "\n",
      "evaluate time:\n",
      "\t\t-elapsed: 1.1452140808105469\n",
      "Epoch [2/2]; Batch [1/5]:\n",
      "\tTrain loss  : 1.097\n",
      "\tVal loss    : 1.099\n",
      "\tTrain acc   : 0.344\n",
      "\tVal acc     : 33.6\n",
      "\tBest val acc: 34.0\n",
      "\tBest model  : epoch_1_batch_3.pt\n",
      "\tElapsed     : 1.233088493347168 s\n",
      "\n",
      "evaluate time:\n",
      "\t\t-elapsed: 1.3716437816619873\n",
      "Epoch [2/2]; Batch [3/5]:\n",
      "\tTrain loss  : 1.101\n",
      "\tVal loss    : 1.098\n",
      "\tTrain acc   : 0.312\n",
      "\tVal acc     : 34.0\n",
      "\tBest val acc: 34.0\n",
      "\tBest model  : epoch_1_batch_3.pt\n",
      "\tElapsed     : 1.410137414932251 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_params_key = ['premise', 'hypo', 'premise_len', 'hypo_len', 'targets']\n",
    "train_helper = train_helpers.TrainHelper(snli_model_rnn_pack, loss_fn, optimizer, batch_params_key, 'rnn_model')\n",
    "out = train_helper.train_loop(train_loader, val_loader, 2, save_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3624,  0.5362,  0.2572,  0.1362],\n",
       "         [ 0.1073,  0.2563,  0.9236,  0.1551],\n",
       "         [ 0.5120,  0.8264,  0.9184,  0.9055]],\n",
       "\n",
       "        [[ 0.9326,  0.7553,  0.1436,  0.5508],\n",
       "         [ 0.0753,  0.2618,  0.5464,  0.6401],\n",
       "         [ 0.0592,  0.4117,  0.6657,  0.4487]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = 2\n",
    "S = 3\n",
    "C = 4\n",
    "a = torch.rand(B, S, C)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.3624,  0.1073,  0.5120],\n",
      "         [ 0.5362,  0.2563,  0.8264],\n",
      "         [ 0.2572,  0.9236,  0.9184],\n",
      "         [ 0.1362,  0.1551,  0.9055]],\n",
      "\n",
      "        [[ 0.9326,  0.0753,  0.0592],\n",
      "         [ 0.7553,  0.2618,  0.4117],\n",
      "         [ 0.1436,  0.5464,  0.6657],\n",
      "         [ 0.5508,  0.6401,  0.4487]]])\n"
     ]
    }
   ],
   "source": [
    "print(a.transpose(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.3624,  0.1073,  0.5120],\n",
      "         [ 0.5362,  0.2563,  0.8264],\n",
      "         [ 0.2572,  0.9236,  0.9184],\n",
      "         [ 0.1362,  0.1551,  0.9055]],\n",
      "\n",
      "        [[ 0.9326,  0.0753,  0.0592],\n",
      "         [ 0.7553,  0.2618,  0.4117],\n",
      "         [ 0.1436,  0.5464,  0.6657],\n",
      "         [ 0.5508,  0.6401,  0.4487]]])\n"
     ]
    }
   ],
   "source": [
    "print(a.transpose(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1=None\n",
    "net2=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(net1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: epoch_1_batch_499.pt\n",
      "\tAcc:  35.2\n",
      "\tLoss:  1.0965064764022827\n",
      "\n",
      "model: epoch_1_batch_999.pt\n",
      "\tAcc:  39.1\n",
      "\tLoss:  1.09356689453125\n",
      "\n",
      "model: epoch_1_batch_1499.pt\n",
      "\tAcc:  46.3\n",
      "\tLoss:  1.0887209177017212\n",
      "\n",
      "model: epoch_1_batch_1999.pt\n",
      "\tAcc:  44.6\n",
      "\tLoss:  1.0817081928253174\n",
      "\n",
      "model: epoch_1_batch_2499.pt\n",
      "\tAcc:  46.4\n",
      "\tLoss:  1.0731196403503418\n",
      "\n",
      "model: epoch_1_batch_2999.pt\n",
      "\tAcc:  48.1\n",
      "\tLoss:  1.064650058746338\n",
      "\n",
      "model: epoch_2_batch_499.pt\n",
      "\tAcc:  48.0\n",
      "\tLoss:  1.049410343170166\n",
      "\n",
      "model: epoch_2_batch_999.pt\n",
      "\tAcc:  47.5\n",
      "\tLoss:  1.0386450290679932\n",
      "\n",
      "model: epoch_2_batch_1499.pt\n",
      "\tAcc:  48.7\n",
      "\tLoss:  1.0296701192855835\n",
      "\n",
      "model: epoch_2_batch_1999.pt\n",
      "\tAcc:  50.5\n",
      "\tLoss:  1.017623782157898\n",
      "\n",
      "model: epoch_2_batch_2499.pt\n",
      "\tAcc:  49.0\n",
      "\tLoss:  1.0154445171356201\n",
      "\n",
      "model: epoch_2_batch_2999.pt\n",
      "\tAcc:  51.2\n",
      "\tLoss:  1.0078098773956299\n",
      "\n",
      "model: epoch_3_batch_499.pt\n",
      "\tAcc:  49.6\n",
      "\tLoss:  1.0009291172027588\n",
      "\n",
      "model: epoch_3_batch_999.pt\n",
      "\tAcc:  51.4\n",
      "\tLoss:  1.0061918497085571\n",
      "\n",
      "model: epoch_3_batch_1499.pt\n",
      "\tAcc:  50.9\n",
      "\tLoss:  0.9940887093544006\n",
      "\n",
      "model: epoch_3_batch_1999.pt\n",
      "\tAcc:  51.6\n",
      "\tLoss:  0.9915248155593872\n",
      "\n",
      "model: epoch_3_batch_2499.pt\n",
      "\tAcc:  51.2\n",
      "\tLoss:  0.9874739050865173\n",
      "\n",
      "model: epoch_3_batch_2999.pt\n",
      "\tAcc:  51.4\n",
      "\tLoss:  0.9900692105293274\n",
      "\n",
      "model: epoch_4_batch_499.pt\n",
      "\tAcc:  51.4\n",
      "\tLoss:  0.9852825999259949\n",
      "\n",
      "model: epoch_4_batch_999.pt\n",
      "\tAcc:  52.7\n",
      "\tLoss:  0.9767866134643555\n",
      "\n",
      "model: epoch_4_batch_1499.pt\n",
      "\tAcc:  52.4\n",
      "\tLoss:  0.9827160835266113\n",
      "\n",
      "model: epoch_4_batch_1999.pt\n",
      "\tAcc:  52.6\n",
      "\tLoss:  0.9900665283203125\n",
      "\n",
      "model: epoch_4_batch_2499.pt\n",
      "\tAcc:  50.9\n",
      "\tLoss:  0.9754347205162048\n",
      "\n",
      "model: epoch_4_batch_2999.pt\n",
      "\tAcc:  51.4\n",
      "\tLoss:  0.9834153056144714\n",
      "\n",
      "model: epoch_5_batch_499.pt\n",
      "\tAcc:  52.6\n",
      "\tLoss:  0.978502631187439\n",
      "\n",
      "model: epoch_5_batch_999.pt\n",
      "\tAcc:  52.9\n",
      "\tLoss:  0.9819384813308716\n",
      "\n",
      "model: epoch_5_batch_1499.pt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-f55b6e13a03b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'rnn_model_500_cat/epoch_{epoch}_batch_{i}.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mhelper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainHelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_params_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\tAcc: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\tLoss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/nyu/2y/nlp/homeworks/hw2/train_helpers.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, loader, accuracy)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/nyu/2y/nlp/homeworks/hw2/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, premise, hypo, premise_len, hypo_len)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/nyu/2y/nlp/homeworks/hw2/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, X_len)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mh_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mpacked_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_X_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#(B, T, D * H), (L * D, B, H)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (B, D*L*H)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3.6/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3.6/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3.6/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3.6/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3.6/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3.6/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mGRUCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mgi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mgh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mi_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mh_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py3.6/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = 500\n",
    "for epoch in range(1, 7):\n",
    "    for i in range(499, 3000, 500):\n",
    "        print('model: ' + f'epoch_{epoch}_batch_{i}.pt')\n",
    "        net = models.SNLI_Model_RNN(ind2vec, 300, hidden_size, hidden_size, 80, 1, True)\n",
    "        net.load_state_dict(torch.load(f'rnn_model_500_cat/epoch_{epoch}_batch_{i}.pt'))\n",
    "        helper = train_helpers.TrainHelper(net, loss_fn, optimizer, batch_params_key)\n",
    "        print(\"\\tAcc: \", helper.evaluate(val_loader, accuracy=True))\n",
    "        print(\"\\tLoss: \", helper.evaluate(val_loader, accuracy=False))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc:  35.7\n",
      "Loss:  35.5\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc:  51.6\n",
      "Loss:  0.983454167842865\n"
     ]
    }
   ],
   "source": [
    "helper.model = net2\n",
    "print(\"Acc: \", helper.evaluate(val_loader, accuracy=True))\n",
    "print(\"Loss: \", helper.evaluate(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3.6]",
   "language": "python",
   "name": "conda-env-py3.6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
